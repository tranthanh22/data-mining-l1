{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4788a25",
   "metadata": {},
   "source": [
    "# Preprocessing Digital Image Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5884603c",
   "metadata": {},
   "source": [
    "## Data Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c192b8",
   "metadata": {},
   "source": [
    "### Loading and Resizing\n",
    "+ Load images from the selected dataset\n",
    "+ Resize images to a consistent dimension\n",
    "+ Explain the rationale for choosing the specific dimensions\n",
    "+ Discuss the trade-offs between image size and computational efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3be440b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Imports & Config\n",
    "# =====================================================\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "ROOT_DIR = r\"C:/Users/GEED/Documents/data-mining-l1/data/images/New Plant Diseases Dataset(Augmented)/train\"\n",
    "\n",
    "# =====================================================\n",
    "# ImageDataset\n",
    "# =====================================================\n",
    "class ImageDataset:\n",
    "    def __init__(self, root_dir, target_size=(224, 224),\n",
    "                 use_augmentation=False, normalize=True,\n",
    "                 subset_ratio=1.0, seed=42):\n",
    "        self.root_dir = root_dir\n",
    "        self.target_size = target_size\n",
    "        self.use_augmentation = use_augmentation\n",
    "        self.normalize = normalize\n",
    "\n",
    "        if not os.path.isdir(root_dir):\n",
    "            raise ValueError(f\"Invalid directory: {root_dir}\")\n",
    "\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.class_to_idx = {}\n",
    "        self.idx_to_class = {}\n",
    "\n",
    "        supported_ext = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp')\n",
    "\n",
    "        classes = sorted([\n",
    "            d for d in os.listdir(root_dir)\n",
    "            if os.path.isdir(os.path.join(root_dir, d))\n",
    "        ])\n",
    "\n",
    "        if not classes:\n",
    "            raise ValueError(\"No class subdirectories found\")\n",
    "\n",
    "        for idx, cls in enumerate(classes):\n",
    "            self.class_to_idx[cls] = idx\n",
    "            self.idx_to_class[idx] = cls\n",
    "\n",
    "            cls_dir = os.path.join(root_dir, cls)\n",
    "            for f in os.listdir(cls_dir):\n",
    "                if f.lower().endswith(supported_ext):\n",
    "                    self.image_paths.append(os.path.join(cls_dir, f))\n",
    "                    self.labels.append(idx)\n",
    "\n",
    "        if subset_ratio < 1.0:\n",
    "            random.seed(seed)\n",
    "            total = len(self.image_paths)\n",
    "            subset_size = int(total * subset_ratio)\n",
    "\n",
    "            indices = list(range(total))\n",
    "            random.shuffle(indices)\n",
    "            selected = indices[:subset_size]\n",
    "\n",
    "            self.image_paths = [self.image_paths[i] for i in selected]\n",
    "            self.labels = [self.labels[i] for i in selected]\n",
    "\n",
    "            print(f\"âœ“ Using subset: {subset_size}/{total} images ({subset_ratio*100:.0f}%)\")\n",
    "\n",
    "        print(f\"âœ“ Dataset loaded: {len(self.image_paths)} images, {len(classes)} classes\")\n",
    "\n",
    "    def augment(self, image):\n",
    "        if random.random() < 0.5:\n",
    "            image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            image = image.rotate(random.uniform(-15, 15))\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            image = ImageEnhance.Brightness(image).enhance(random.uniform(0.8, 1.2))\n",
    "            image = ImageEnhance.Contrast(image).enhance(random.uniform(0.8, 1.2))\n",
    "            image = ImageEnhance.Color(image).enhance(random.uniform(0.8, 1.2))\n",
    "\n",
    "        return image\n",
    "\n",
    "    def load_image(self, idx):\n",
    "        try:\n",
    "            img_path = self.image_paths[idx]\n",
    "\n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, self.target_size)\n",
    "\n",
    "            image = Image.fromarray(image)\n",
    "\n",
    "            if self.use_augmentation:\n",
    "                image = self.augment(image)\n",
    "\n",
    "            image = np.asarray(image, dtype=np.float32) / 255.0\n",
    "\n",
    "            if self.normalize:\n",
    "                mean = np.array([0.485, 0.456, 0.406])\n",
    "                std = np.array([0.229, 0.224, 0.225])\n",
    "                image = (image - mean) / std\n",
    "\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "            return image, self.labels[idx]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image: {e}\")\n",
    "            blank = np.zeros((3, *self.target_size), dtype=np.float32)\n",
    "            return blank, self.labels[idx]\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# DataLoader\n",
    "# =====================================================\n",
    "class DataLoader:\n",
    "    def __init__(self, dataset, batch_size=32, shuffle=True):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(dataset.image_paths))\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "        for start in range(0, len(self.indices), self.batch_size):\n",
    "            batch_idx = self.indices[start:start + self.batch_size]\n",
    "\n",
    "            images, labels = [], []\n",
    "            for idx in batch_idx:\n",
    "                img, lbl = self.dataset.load_image(idx)\n",
    "                images.append(img)\n",
    "                labels.append(lbl)\n",
    "\n",
    "            yield np.stack(images), np.array(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices) // self.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61386779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Dataset loaded: 70295 images, 38 classes\n",
      "âœ“ Total images: 70295\n",
      "âœ“ Classes: 38\n",
      "âœ“ Batches per epoch: 2196\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# Pipeline builder\n",
    "# =====================================================\n",
    "def build_image_pipeline(\n",
    "    root_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    use_augmentation=False,\n",
    "    normalize=True,\n",
    "    subset_ratio=1.0,\n",
    "    seed=42,\n",
    "):\n",
    "    dataset = ImageDataset(\n",
    "        root_dir=root_dir,\n",
    "        target_size=target_size,\n",
    "        use_augmentation=use_augmentation,\n",
    "        normalize=normalize,\n",
    "        subset_ratio=subset_ratio,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "\n",
    "    print(f\"âœ“ Total images: {len(dataset.image_paths)}\")\n",
    "    print(f\"âœ“ Classes: {len(dataset.class_to_idx)}\")\n",
    "    print(f\"âœ“ Batches per epoch: {len(loader)}\")\n",
    "\n",
    "    return dataset, loader\n",
    "\n",
    "# ---- Khá»Ÿi táº¡o dataset & loader (cháº¡y cell nÃ y lÃ  loader tá»“n táº¡i)\n",
    "dataset, loader = build_image_pipeline(\n",
    "    root_dir=ROOT_DIR,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    normalize=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83f6b022",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70295/70295 [00:44<00:00, 1564.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved 70295/70295 images\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# Standalone resize & save\n",
    "# =====================================================\n",
    "OUTPUT_ROOT = r\"C:/Users/GEED/Documents/data-mining-l1/data/images/subset_resized_224\"\n",
    "TARGET_SIZE = (224, 224)\n",
    "NUM_WORKERS = min(16, os.cpu_count() * 2)\n",
    "\n",
    "os.makedirs(OUTPUT_ROOT, exist_ok=True)\n",
    "\n",
    "def resize_and_save(img_path, label):\n",
    "    try:\n",
    "        class_name = dataset.idx_to_class[label]\n",
    "        out_dir = os.path.join(OUTPUT_ROOT, class_name)\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "        out_path = os.path.join(out_dir, os.path.basename(img_path))\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            return False\n",
    "\n",
    "        img = cv2.resize(img, TARGET_SIZE)\n",
    "        return cv2.imwrite(out_path, img)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "tasks = list(zip(dataset.image_paths, dataset.labels))\n",
    "\n",
    "success = 0\n",
    "with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:\n",
    "    futures = [\n",
    "        executor.submit(resize_and_save, p, l)\n",
    "        for p, l in tasks\n",
    "    ]\n",
    "\n",
    "    for f in tqdm(as_completed(futures), total=len(futures)):\n",
    "        if f.result():\n",
    "            success += 1\n",
    "\n",
    "print(f\"âœ… Saved {success}/{len(tasks)} images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251d38f8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d5dd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from scipy import ndimage\n",
    "import time\n",
    "\n",
    "def resize_image(img, size=(224,224), method=cv2.INTER_LINEAR):\n",
    "    return cv2.resize(img, size, interpolation=method)\n",
    "\n",
    "def measure_performance(func, *args):\n",
    "    start = time.time()\n",
    "    out = func(*args)\n",
    "    elapsed = (time.time() - start) * 1000\n",
    "    memory = out.nbytes / 1024\n",
    "    return out, elapsed, memory\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213a855f",
   "metadata": {},
   "source": [
    "### Grayscale Conversion\n",
    "+ Convert color images to grayscale where appropriate\n",
    "+ Compare information retention between color and grayscale representations\n",
    "+ Discuss when grayscale conversion is beneficial versus detrimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1b978d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size      : 70295 images\n",
      "Number of classes : 38\n",
      "Batches / epoch   : 2196\n",
      "\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2196 [00:00<04:42,  7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RGB batch shape : (32, 3, 224, 224)\n",
      " Gray batch shape: (32, 1, 224, 224)\n",
      " Gray batch shape: (32, 1, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2197it [03:39, 10.00it/s]                          \n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# Grayscale processing - FULL EPOCH\n",
    "# Dataset: 70,295 images | 38 classes | 2,196 batches/epoch\n",
    "# =====================================================\n",
    "\n",
    "NUM_EPOCHS = 1  # Ä‘á»•i náº¿u cáº§n\n",
    "\n",
    "print(f\"Dataset size      : {len(dataset.image_paths)} images\")\n",
    "print(f\"Number of classes : {len(dataset.class_to_idx)}\")\n",
    "print(f\"Batches / epoch   : {len(loader)}\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(tqdm(loader, total=len(loader))):\n",
    "        gray_images = (\n",
    "            0.299 * images[:, 0] +\n",
    "            0.587 * images[:, 1] +\n",
    "            0.114 * images[:, 2]\n",
    "        )\n",
    "\n",
    "        gray_images = gray_images[:, None, :, :]\n",
    "\n",
    "        if batch_idx == 0:\n",
    "            print(\" RGB batch shape :\", images.shape)\n",
    "            print(\" Gray batch shape:\", gray_images.shape)\n",
    "\n",
    "            print(\" Gray batch shape:\", gray_images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d3050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_gray_luminance(img):\n",
    "    return 0.299*img[:,:,0] + 0.587*img[:,:,1] + 0.114*img[:,:,2]\n",
    "\n",
    "def mutual_information(rgb, gray):\n",
    "    rgb_flat = rgb.mean(axis=2).ravel()\n",
    "    gray_flat = gray.ravel()\n",
    "    return mutual_info_score(rgb_flat, gray_flat)\n",
    "\n",
    "def information_retention(ssim_val, mi, mi_max):\n",
    "    mi_norm = mi / mi_max\n",
    "    return (ssim_val + mi_norm) / 2 * 100\n",
    "\n",
    "def gray_variance(gray):\n",
    "    return np.var(gray)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86c2d54",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "+ Normalization: Apply pixel normalization (e.g., scaling to [0,1] or [-1,1]) and implement standardization (zero mean, unit variance).\n",
    "+ Compare different normalization techniques and their effects on the data distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d4a38f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gray shape        : (23, 1, 224, 224)\n",
      "Gray norm shape   : (23, 1, 224, 224)\n",
      "Mean after norm   : -2.728764665671414e-17\n",
      "Std after norm    : 0.9999988376733839\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# Grayscale Normalization - Batch-wise\n",
    "# Input : gray_images (B, 1, H, W)\n",
    "# Output: gray_norm   (B, 1, H, W)\n",
    "# =====================================================\n",
    "\n",
    "def normalize_gray_batchwise(gray, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Chuáº©n hÃ³a grayscale theo toÃ n batch (batch-wise normalization)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gray : np.ndarray\n",
    "        Grayscale images, shape (B, 1, H, W)\n",
    "    eps : float\n",
    "        Há»‡ sá»‘ nhá» Ä‘á»ƒ trÃ¡nh chia cho 0\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    gray_norm : np.ndarray\n",
    "        Grayscale Ä‘Ã£ Ä‘Æ°á»£c chuáº©n hÃ³a\n",
    "    \"\"\"\n",
    "    mean = gray.mean(axis=(0, 1, 2, 3), keepdims=True)\n",
    "    std  = gray.std(axis=(0, 1, 2, 3), keepdims=True)\n",
    "    return (gray - mean) / (std + eps)\n",
    "\n",
    "\n",
    "# ---- Ãp dá»¥ng normalization cho batch grayscale\n",
    "gray_norm = normalize_gray_batchwise(gray_images)\n",
    "\n",
    "# ---- DEBUG nhanh (chá»‰ kiá»ƒm tra batch Ä‘áº§u)\n",
    "print(\"Gray shape        :\", gray_images.shape)\n",
    "print(\"Gray norm shape   :\", gray_norm.shape)\n",
    "print(\"Mean after norm   :\", gray_norm.mean())\n",
    "print(\"Std after norm    :\", gray_norm.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6d1032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_norm(img):\n",
    "    return (img - img.min()) / (img.max() - img.min() + 1e-6)\n",
    "\n",
    "def zscore_norm(img):\n",
    "    return (img - img.mean()) / (img.std() + 1e-6)\n",
    "\n",
    "def describe(img):\n",
    "    return {\n",
    "        \"min\": img.min(),\n",
    "        \"max\": img.max(),\n",
    "        \"mean\": img.mean(),\n",
    "        \"median\": np.median(img),\n",
    "        \"std\": img.std()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8396d3d",
   "metadata": {},
   "source": [
    "### Edge Detection (Optional Bonus)\n",
    "+ Apply edge detection algorithms (Sobel, Prewitt, Canny)\n",
    "+ Extract edge features from images, and then visualize detected edges and discuss their significance for your\n",
    "chosen dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69c89dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Edge Detection - Batch-wise (Unified Version)\n",
    "# Input : gray_norm (B, 1, H, W)\n",
    "# Output: edges     (B, H, W)\n",
    "# =====================================================\n",
    "\n",
    "def sobel_edges(gray_norm):\n",
    "    \"\"\"\n",
    "    Sobel edge detection cho grayscale Ä‘Ã£ normalize batch-wise\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gray_norm : np.ndarray\n",
    "        Shape (B, 1, H, W)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    edges : np.ndarray\n",
    "        Shape (B, H, W)\n",
    "    \"\"\"\n",
    "    gray = gray_norm[:, 0]  # (B, H, W)\n",
    "    edges = []\n",
    "\n",
    "    for g in gray:\n",
    "        sx = ndimage.sobel(g, axis=0)\n",
    "        sy = ndimage.sobel(g, axis=1)\n",
    "        edges.append(np.hypot(sx, sy))\n",
    "\n",
    "    return np.stack(edges)\n",
    "\n",
    "\n",
    "def prewitt_edges(gray_norm):\n",
    "    \"\"\"\n",
    "    Prewitt edge detection cho grayscale Ä‘Ã£ normalize batch-wise\n",
    "    \"\"\"\n",
    "    gray = gray_norm[:, 0]\n",
    "    edges = []\n",
    "\n",
    "    for g in gray:\n",
    "        px = ndimage.prewitt(g, axis=0)\n",
    "        py = ndimage.prewitt(g, axis=1)\n",
    "        edges.append(np.hypot(px, py))\n",
    "\n",
    "    return np.stack(edges)\n",
    "\n",
    "\n",
    "def canny_edges(gray_norm, low=50, high=150):\n",
    "    \"\"\"\n",
    "    Canny edge detection (cáº§n uint8 [0,255])\n",
    "    \"\"\"\n",
    "    gray = gray_norm[:, 0]\n",
    "    edges = []\n",
    "\n",
    "    for g in gray:\n",
    "        g_uint8 = cv2.normalize(\n",
    "            g, None, 0, 255, cv2.NORM_MINMAX\n",
    "        ).astype(np.uint8)\n",
    "\n",
    "        edges.append(cv2.Canny(g_uint8, low, high))\n",
    "\n",
    "    return np.stack(edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f29e58ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_edges(gray, edges, idx=0, title=\"Edges\"):\n",
    "    \"\"\"\n",
    "    Visualize grayscale vÃ  edge map tÆ°Æ¡ng á»©ng\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gray : np.ndarray\n",
    "        (B, 1, H, W) hoáº·c (B, H, W)\n",
    "    edges : np.ndarray\n",
    "        (B, H, W)\n",
    "    idx : int\n",
    "        Index áº£nh trong batch\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- Ä‘áº£m báº£o Ä‘Ãºng shape Ä‘á»ƒ váº½\n",
    "    if gray.ndim == 4:\n",
    "        gray_img = gray[idx, 0]\n",
    "    else:\n",
    "        gray_img = gray[idx]\n",
    "\n",
    "    edge_img = edges[idx]\n",
    "\n",
    "    # ---- rescale Ä‘á»ƒ hiá»ƒn thá»‹\n",
    "    gray_img = (gray_img - gray_img.min()) / (gray_img.ptp() + 1e-6)\n",
    "    edge_img = (edge_img - edge_img.min()) / (edge_img.ptp() + 1e-6)\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(gray_img, cmap=\"gray\")\n",
    "    plt.title(\"Grayscale\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(edge_img, cmap=\"gray\")\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8476b230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_coverage(edge):\n",
    "    return np.count_nonzero(edge) / edge.size * 100\n",
    "\n",
    "def mean_edge_intensity(edge):\n",
    "    return edge[edge > 0].mean()\n",
    "\n",
    "def edge_density_per_class(edges_by_class):\n",
    "    return np.mean([edge_coverage(e) for e in edges_by_class])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adee765",
   "metadata": {},
   "source": [
    "Main Function for testing purpose and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3276da34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(\n",
    "    loader,\n",
    "    edge_method=\"sobel\",\n",
    "    visualize=True,\n",
    "    vis_idx=0,\n",
    "    max_batches=1\n",
    "):\n",
    "    \"\"\"\n",
    "    Main pipeline xá»­ lÃ½ áº£nh:\n",
    "    RGB â†’ Grayscale â†’ Normalize â†’ Edge detection â†’ (Visualize)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    loader : DataLoader\n",
    "        DataLoader Ä‘Ã£ Ä‘Æ°á»£c build sáºµn\n",
    "    edge_method : str\n",
    "        \"sobel\" | \"prewitt\" | \"canny\"\n",
    "    visualize : bool\n",
    "        CÃ³ hiá»ƒn thá»‹ káº¿t quáº£ hay khÃ´ng\n",
    "    vis_idx : int\n",
    "        Index áº£nh trong batch Ä‘á»ƒ visualize\n",
    "    max_batches : int\n",
    "        Sá»‘ batch xá»­ lÃ½ (debug nhanh, trÃ¡nh cháº¡y toÃ n bá»™ dataset)\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"ðŸš€ Starting image processing pipeline\")\n",
    "    print(f\"Edge method   : {edge_method}\")\n",
    "    print(f\"Visualize     : {visualize}\")\n",
    "    print(f\"Max batches   : {max_batches}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(loader):\n",
    "\n",
    "        # ---- 1. RGB â†’ Grayscale (luminance)\n",
    "        gray = (\n",
    "            0.299 * images[:, 0] +\n",
    "            0.587 * images[:, 1] +\n",
    "            0.114 * images[:, 2]\n",
    "        )\n",
    "        gray = gray[:, None, :, :]   # (B, 1, H, W)\n",
    "\n",
    "        # ---- 2. Normalize grayscale (batch-wise)\n",
    "        gray_norm = normalize_gray_batchwise(gray)\n",
    "\n",
    "        # ---- 3. Chuáº©n bá»‹ cho edge detection\n",
    "        gray_for_edge = gray_norm[:, 0]   # (B, H, W)\n",
    "\n",
    "        # ---- 4. Edge detection\n",
    "        if edge_method == \"sobel\":\n",
    "            edges = sobel_edges_batchwise(gray_for_edge)\n",
    "            edge_title = \"Sobel edges\"\n",
    "\n",
    "        elif edge_method == \"prewitt\":\n",
    "            edges = prewitt_edges_batchwise(gray_for_edge)\n",
    "            edge_title = \"Prewitt edges\"\n",
    "\n",
    "        elif edge_method == \"canny\":\n",
    "            edges = canny_edges_per_image(gray_for_edge)\n",
    "            edge_title = \"Canny edges\"\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"edge_method must be 'sobel', 'prewitt', or 'canny'\")\n",
    "\n",
    "        # ---- 5. Visualization (optional)\n",
    "        if visualize:\n",
    "            visualize_edges(\n",
    "                gray_norm,\n",
    "                edges,\n",
    "                idx=vis_idx,\n",
    "                title=edge_title\n",
    "            )\n",
    "\n",
    "        # ---- 6. ThoÃ¡t sá»›m náº¿u debug\n",
    "        if batch_idx + 1 >= max_batches:\n",
    "            break\n",
    "\n",
    "    print(\"âœ… Pipeline finished\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5869e50b",
   "metadata": {},
   "source": [
    "Image (RGB)\n",
    " â†’ Resize\n",
    " â†’ Normalize\n",
    " â†’ Grayscale\n",
    " â†’ Gray Normalization\n",
    " â†’ Edge Detection\n",
    " â†’ Visualization / Feature Extraction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imgproc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
