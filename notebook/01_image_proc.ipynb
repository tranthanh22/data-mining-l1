{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4788a25",
   "metadata": {},
   "source": [
    "# Preprocessing Digital Image Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5884603c",
   "metadata": {},
   "source": [
    "## Data Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c192b8",
   "metadata": {},
   "source": [
    "### Loading and Resizing\n",
    "+ Load images from the selected dataset\n",
    "+ Resize images to a consistent dimension\n",
    "+ Explain the rationale for choosing the specific dimensions\n",
    "+ Discuss the trade-offs between image size and computational efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f6b022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageEnhance\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff31fefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Using subset: 7029/70295 images (10%)\n",
      "✓ Dataset loaded: 7029 images, 38 classes\n",
      "✓ Total images: 7029\n",
      "✓ Classes: 38\n",
      "✓ Batches per epoch: 219\n",
      "✓ Batch loaded\n",
      "Images shape: (32, 3, 224, 224)\n",
      "Labels shape: (32,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7029/7029 [00:06<00:00, 1111.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 7029/7029 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ImageDataset:\n",
    "    def __init__(self, root_dir, target_size=(224, 224),\n",
    "                 use_augmentation=False, normalize=True,\n",
    "                 subset_ratio=1.0, seed=42):\n",
    "        self.root_dir = root_dir\n",
    "        self.target_size = target_size\n",
    "        self.use_augmentation = use_augmentation\n",
    "        self.normalize = normalize\n",
    "\n",
    "        if not os.path.isdir(root_dir):\n",
    "            raise ValueError(f\"Invalid directory: {root_dir}\")\n",
    "\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.class_to_idx = {}\n",
    "        self.idx_to_class = {}\n",
    "\n",
    "        supported_ext = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp')\n",
    "\n",
    "        classes = sorted([\n",
    "            d for d in os.listdir(root_dir)\n",
    "            if os.path.isdir(os.path.join(root_dir, d))\n",
    "        ])\n",
    "\n",
    "        if not classes:\n",
    "            raise ValueError(\"No class subdirectories found\")\n",
    "\n",
    "        for idx, cls in enumerate(classes):\n",
    "            self.class_to_idx[cls] = idx\n",
    "            self.idx_to_class[idx] = cls\n",
    "\n",
    "            cls_dir = os.path.join(root_dir, cls)\n",
    "            for f in os.listdir(cls_dir):\n",
    "                if f.lower().endswith(supported_ext):\n",
    "                    self.image_paths.append(os.path.join(cls_dir, f))\n",
    "                    self.labels.append(idx)\n",
    "        if subset_ratio < 1.0:\n",
    "            random.seed(seed)\n",
    "            total = len(self.image_paths)\n",
    "            subset_size = int(total * subset_ratio)\n",
    "\n",
    "            indices = list(range(total))\n",
    "            random.shuffle(indices)\n",
    "            selected = indices[:subset_size]\n",
    "\n",
    "            self.image_paths = [self.image_paths[i] for i in selected]\n",
    "            self.labels = [self.labels[i] for i in selected]\n",
    "\n",
    "        print(f\"✓ Using subset: {subset_size}/{total} images ({subset_ratio*100:.0f}%)\")\n",
    "        print(f\"✓ Dataset loaded: {len(self.image_paths)} images, {len(classes)} classes\")\n",
    "\n",
    "    def augment(self, image):\n",
    "        # Random horizontal flip\n",
    "        if random.random() < 0.5:\n",
    "            image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "        # Random rotation\n",
    "        if random.random() < 0.5:\n",
    "            angle = random.uniform(-15, 15)\n",
    "            image = image.rotate(angle)\n",
    "\n",
    "        # Color jitter\n",
    "        if random.random() < 0.5:\n",
    "            image = ImageEnhance.Brightness(image).enhance(random.uniform(0.8, 1.2))\n",
    "            image = ImageEnhance.Contrast(image).enhance(random.uniform(0.8, 1.2))\n",
    "            image = ImageEnhance.Color(image).enhance(random.uniform(0.8, 1.2))\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "    def load_image(self, idx):\n",
    "        try:\n",
    "            img_path = self.image_paths[idx]\n",
    "\n",
    "            # OpenCV đọc nhanh hơn\n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, self.target_size)\n",
    "\n",
    "            image = Image.fromarray(image)\n",
    "\n",
    "            if self.use_augmentation:\n",
    "                image = self.augment(image)\n",
    "\n",
    "            image = np.asarray(image, dtype=np.float32) / 255.0  # [0,1]\n",
    "\n",
    "            if self.normalize:\n",
    "                mean = np.array([0.485, 0.456, 0.406])\n",
    "                std = np.array([0.229, 0.224, 0.225])\n",
    "                image = (image - mean) / std\n",
    "\n",
    "            # CHW format (giống PyTorch)\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "\n",
    "            return image, self.labels[idx]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image: {e}\")\n",
    "            blank = np.zeros((3, *self.target_size), dtype=np.float32)\n",
    "            return blank, self.labels[idx]\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, dataset, batch_size=32, shuffle=True):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(dataset.image_paths))\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "        for start in range(0, len(self.indices), self.batch_size):\n",
    "            batch_idx = self.indices[start:start + self.batch_size]\n",
    "\n",
    "            images, labels = [], []\n",
    "            for idx in batch_idx:\n",
    "                img, lbl = self.dataset.load_image(idx)\n",
    "                images.append(img)\n",
    "                labels.append(lbl)\n",
    "\n",
    "            yield np.stack(images), np.array(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices) // self.batch_size\n",
    "\n",
    "def build_image_pipeline(\n",
    "    root_dir,\n",
    "    output_dir=None,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    use_augmentation=False,\n",
    "    normalize=True,\n",
    "    subset_ratio=1.0,\n",
    "    seed=42,\n",
    "    save_resized=False,\n",
    "    num_workers=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Hàm tổng hợp:\n",
    "    - Load dataset\n",
    "    - Tạo DataLoader\n",
    "    - (Optional) Resize & save ảnh ra disk\n",
    "\n",
    "    Returns:\n",
    "        dataset, loader\n",
    "    \"\"\"\n",
    "\n",
    "    # =============================\n",
    "    # 1. Khởi tạo Dataset\n",
    "    # =============================\n",
    "    dataset = ImageDataset(\n",
    "        root_dir=root_dir,\n",
    "        target_size=target_size,\n",
    "        use_augmentation=use_augmentation,\n",
    "        normalize=normalize,\n",
    "        subset_ratio=subset_ratio,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    # =============================\n",
    "    # 2. Khởi tạo DataLoader\n",
    "    # =============================\n",
    "    loader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "\n",
    "    print(f\"✓ Total images: {len(dataset.image_paths)}\")\n",
    "    print(f\"✓ Classes: {len(dataset.class_to_idx)}\")\n",
    "    print(f\"✓ Batches per epoch: {len(loader)}\")\n",
    "\n",
    "    # =============================\n",
    "    # 3. Resize & Save (optional)\n",
    "    # =============================\n",
    "    if save_resized:\n",
    "        if output_dir is None:\n",
    "            raise ValueError(\"output_dir must be provided if save_resized=True\")\n",
    "\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        if num_workers is None:\n",
    "            num_workers = min(16, os.cpu_count() * 2)\n",
    "\n",
    "        print(f\"✓ Saving resized images to: {output_dir}\")\n",
    "        print(f\"✓ Using {num_workers} workers\")\n",
    "\n",
    "        def resize_and_save(img_path, label):\n",
    "            try:\n",
    "                class_name = dataset.idx_to_class[label]\n",
    "                out_dir = os.path.join(output_dir, class_name)\n",
    "                os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "                out_path = os.path.join(out_dir, os.path.basename(img_path))\n",
    "\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    return False\n",
    "\n",
    "                img = cv2.resize(img, target_size)\n",
    "                return cv2.imwrite(out_path, img)\n",
    "\n",
    "            except Exception:\n",
    "                return False\n",
    "\n",
    "        tasks = list(zip(dataset.image_paths, dataset.labels))\n",
    "\n",
    "        success = 0\n",
    "        with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "            futures = [\n",
    "                executor.submit(resize_and_save, p, l)\n",
    "                for p, l in tasks\n",
    "            ]\n",
    "\n",
    "            for f in tqdm(as_completed(futures), total=len(futures)):\n",
    "                if f.result():\n",
    "                    success += 1\n",
    "\n",
    "        print(f\"✅ Saved {success}/{len(tasks)} images\")\n",
    "\n",
    "    return dataset, loader\n",
    "\n",
    "\n",
    "\n",
    "OUTPUT_ROOT = r\"C:/Users/GEED/Documents/data-mining-l1/data/images/subset_resized_224\"\n",
    "TARGET_SIZE = (224, 224)\n",
    "NUM_WORKERS = min(16, os.cpu_count() * 2)\n",
    "\n",
    "os.makedirs(OUTPUT_ROOT, exist_ok=True)\n",
    "\n",
    "def resize_and_save(img_path, label):\n",
    "    try:\n",
    "        class_name = dataset.idx_to_class[label]\n",
    "        out_dir = os.path.join(OUTPUT_ROOT, class_name)\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "        out_path = os.path.join(out_dir, os.path.basename(img_path))\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            return False\n",
    "\n",
    "        img = cv2.resize(img, TARGET_SIZE)\n",
    "        return cv2.imwrite(out_path, img)\n",
    "\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "tasks = list(zip(dataset.image_paths, dataset.labels))\n",
    "\n",
    "success = 0\n",
    "with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:\n",
    "    futures = [executor.submit(resize_and_save, p, l) for p, l in tasks]\n",
    "\n",
    "    for f in tqdm(as_completed(futures), total=len(futures)):\n",
    "        if f.result():\n",
    "            success += 1\n",
    "\n",
    "print(f\"✅ Saved {success}/{len(tasks)} images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213a855f",
   "metadata": {},
   "source": [
    "### Grayscale Conversion\n",
    "+ Convert color images to grayscale where appropriate\n",
    "+ Compare information retention between color and grayscale representations\n",
    "+ Discuss when grayscale conversion is beneficial versus detrimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b978d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_grayscale(images):\n",
    "    # batch: (B, 3, H, W)\n",
    "    r, g, b = images[:, 0], images[:, 1], images[:, 2]\n",
    "    gray = 0.299 * r + 0.587 * g + 0.114 * b\n",
    "    return gray  # (B, H, W)\n",
    "\n",
    "for images, labels in loader:\n",
    "    gray_images = rgb_to_grayscale(images)\n",
    "    print(gray_images.shape)  # (B, 224, 224)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86c2d54",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "+ Normalization: Apply pixel normalization (e.g., scaling to [0,1] or [-1,1]) and implement standardization (zero mean, unit variance).\n",
    "+ Compare different normalization techniques and their effects on the data distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4a38f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the code snippet you provided.\n",
    "# You should replace this comment with the actual code you want me to complete.\n",
    "# Every code you should provide comments to be graded. \n",
    "\n",
    "def normalize_gray_batchwise(gray, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Chuẩn hóa toàn batch chung một mean/std\n",
    "    \"\"\"\n",
    "    mean = gray.mean(axis=(0,1,2), keepdims=True)\n",
    "    std  = gray.std(axis=(0,1,2), keepdims=True)\n",
    "    return (gray - mean) / (std + eps)\n",
    "\n",
    "\n",
    "def normalize_gray_batchwise(gray, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Chuẩn hóa toàn batch chung một mean/std\n",
    "    \"\"\"\n",
    "    mean = gray.mean(axis=(0,1,2), keepdims=True)\n",
    "    std  = gray.std(axis=(0,1,2), keepdims=True)\n",
    "    return (gray - mean) / (std + eps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8396d3d",
   "metadata": {},
   "source": [
    "### Edge Detection (Optional Bonus)\n",
    "+ Apply edge detection algorithms (Sobel, Prewitt, Canny)\n",
    "+ Extract edge features from images, and then visualize detected edges and discuss their significance for your\n",
    "chosen dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c89dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the code snippet you provided.\n",
    "# You should replace this comment with the actual code you want me to complete.\n",
    "# Every code you should provide comments to be graded. \n",
    "def sobel_edges_batchwise(gray):\n",
    "    \"\"\"\n",
    "    Sobel edge detection cho gray đã normalize batchwise\n",
    "    gray: (B, H, W)\n",
    "    return: (B, H, W)\n",
    "    \"\"\"\n",
    "    edges = []\n",
    "    for g in gray:\n",
    "        sx = ndimage.sobel(g, axis=0)\n",
    "        sy = ndimage.sobel(g, axis=1)\n",
    "        edges.append(np.hypot(sx, sy))\n",
    "    return np.stack(edges)\n",
    "\n",
    "def sobel_edges_per_image(gray):\n",
    "    \"\"\"\n",
    "    Sobel edge detection cho gray đã normalize per-image\n",
    "    \"\"\"\n",
    "    edges = []\n",
    "    for g in gray:\n",
    "        sx = ndimage.sobel(g, axis=0)\n",
    "        sy = ndimage.sobel(g, axis=1)\n",
    "        edges.append(np.hypot(sx, sy))\n",
    "    return np.stack(edges)\n",
    "\n",
    "\n",
    "def prewitt_edges_batchwise(gray):\n",
    "    \"\"\"\n",
    "    Prewitt edge detection cho gray đã normalize batchwise\n",
    "    \"\"\"\n",
    "    edges = []\n",
    "    for g in gray:\n",
    "        px = ndimage.prewitt(g, axis=0)\n",
    "        py = ndimage.prewitt(g, axis=1)\n",
    "        edges.append(np.hypot(px, py))\n",
    "    return np.stack(edges)\n",
    "\n",
    "def prewitt_edges_per_image(gray):\n",
    "    \"\"\"\n",
    "    Prewitt edge detection cho gray đã normalize per-image\n",
    "    \"\"\"\n",
    "    edges = []\n",
    "    for g in gray:\n",
    "        px = ndimage.prewitt(g, axis=0)\n",
    "        py = ndimage.prewitt(g, axis=1)\n",
    "        edges.append(np.hypot(px, py))\n",
    "    return np.stack(edges)\n",
    "\n",
    "\n",
    "import cv2\n",
    "\n",
    "def canny_edges_per_image(gray, low=50, high=150):\n",
    "    \"\"\"\n",
    "    Canny edge detection cho gray đã normalize per-image\n",
    "    \"\"\"\n",
    "    edges = []\n",
    "    for g in gray:\n",
    "        # Rescale về [0,255] cho Canny\n",
    "        g_uint8 = cv2.normalize(\n",
    "            g, None, 0, 255, cv2.NORM_MINMAX\n",
    "        ).astype(np.uint8)\n",
    "\n",
    "        edges.append(cv2.Canny(g_uint8, low, high))\n",
    "    return np.stack(edges)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_edges(gray, edges, idx=0, title=\"Edges\"):\n",
    "    \"\"\"\n",
    "    Hiển thị ảnh grayscale và edge\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8,4))\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(gray[idx], cmap=\"gray\")\n",
    "    plt.title(\"Grayscale\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(edges[idx], cmap=\"gray\")\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adee765",
   "metadata": {},
   "source": [
    "Main Function for testing purpose and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3276da34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# MAIN CELL: PIPELINE TEST & VISUALIZATION\n",
    "# ===============================\n",
    "\n",
    "def main_pipeline_test():\n",
    "    \"\"\"\n",
    "    Cell main để:\n",
    "    - Load dataset + dataloader\n",
    "    - RGB → Grayscale\n",
    "    - Normalize grayscale\n",
    "    - Edge detection\n",
    "    - Visualization kết quả\n",
    "    \"\"\"\n",
    "\n",
    "    # ===============================\n",
    "    # 1. Khởi tạo pipeline\n",
    "    # ===============================\n",
    "    TRAIN_ROOT = r\"C:/Users/GEED/Documents/data-mining-l1/data/images/New Plant Diseases Dataset(Augmented)/train\"\n",
    "    OUTPUT_ROOT = r\"C:/Users/GEED/Documents/data-mining-l1/data/images/subset_resized_224\"\n",
    "\n",
    "    dataset, loader = build_image_pipeline(\n",
    "        root_dir=TRAIN_ROOT,\n",
    "        output_dir=OUTPUT_ROOT,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=8,              # nhỏ để visualize\n",
    "        shuffle=True,\n",
    "        use_augmentation=False,    # tắt để dễ quan sát\n",
    "        normalize=True,\n",
    "        subset_ratio=0.1,\n",
    "        save_resized=False         # chỉ test pipeline\n",
    "    )\n",
    "\n",
    "    # ===============================\n",
    "    # 2. Lấy 1 batch\n",
    "    # ===============================\n",
    "    images, labels = next(iter(loader))\n",
    "    print(\"RGB batch shape:\", images.shape)   # (B, 3, 224, 224)\n",
    "\n",
    "    # ===============================\n",
    "    # 3. RGB → Grayscale\n",
    "    # ===============================\n",
    "    gray = rgb_to_grayscale(images)\n",
    "    print(\"Grayscale shape:\", gray.shape)     # (B, 224, 224)\n",
    "\n",
    "    # ===============================\n",
    "    # 4. Normalize grayscale (batchwise)\n",
    "    # ===============================\n",
    "    gray_norm = normalize_gray_batchwise(gray)\n",
    "    print(\"Gray normalized:\",\n",
    "          f\"mean={gray_norm.mean():.4f}, std={gray_norm.std():.4f}\")\n",
    "\n",
    "    # ===============================\n",
    "    # 5. Edge Detection\n",
    "    # ===============================\n",
    "    sobel_edges   = sobel_edges_batchwise(gray_norm)\n",
    "    prewitt_edges = prewitt_edges_batchwise(gray_norm)\n",
    "    canny_edges   = canny_edges_per_image(gray_norm)\n",
    "\n",
    "    print(\"Sobel edges shape:\", sobel_edges.shape)\n",
    "    print(\"Prewitt edges shape:\", prewitt_edges.shape)\n",
    "    print(\"Canny edges shape:\", canny_edges.shape)\n",
    "\n",
    "    # ===============================\n",
    "    # 6. Visualization\n",
    "    # ===============================\n",
    "    visualize_edges(gray_norm, sobel_edges, idx=0, title=\"Sobel Edges\")\n",
    "    visualize_edges(gray_norm, prewitt_edges, idx=0, title=\"Prewitt Edges\")\n",
    "    visualize_edges(gray_norm, canny_edges, idx=0, title=\"Canny Edges\")\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# RUN MAIN\n",
    "# ===============================\n",
    "main_pipeline_test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5869e50b",
   "metadata": {},
   "source": [
    "Image (RGB)\n",
    " → Resize\n",
    " → Normalize\n",
    " → Grayscale\n",
    " → Gray Normalization\n",
    " → Edge Detection\n",
    " → Visualization / Feature Extraction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
